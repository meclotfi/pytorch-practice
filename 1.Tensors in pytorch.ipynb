{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are similar to NumPyâ€™s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4972e-11,  7.0205e-43, -2.3531e-12,  7.0205e-43,  0.0000e+00,\n",
      "          0.0000e+00,  2.1019e-44,  0.0000e+00, -1.5229e-11],\n",
      "        [ 7.0205e-43,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          2.1019e-44,  0.0000e+00, -1.2703e-11,  7.0205e-43],\n",
      "        [ 1.7796e-43,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1019e-44,\n",
      "          0.0000e+00, -2.4279e-11,  7.0205e-43,  1.7796e-43],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00,\n",
      "         -1.1159e-12,  7.0205e-43,  1.7796e-43,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00, -2.2811e-11,\n",
      "          7.0205e-43,  1.7796e-43,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  2.1019e-44,  0.0000e+00, -2.4791e-11,  7.0205e-43,\n",
      "          1.7796e-43,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.empty(6,9)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1480, 0.9864, 0.2354],\n",
      "        [0.3847, 0.3259, 0.5614],\n",
      "        [0.2336, 0.4544, 0.3184],\n",
      "        [0.8569, 0.2899, 0.0944],\n",
      "        [0.9296, 0.7840, 0.6513]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.rand(5,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.zeros(5,3,dtype=torch.long)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a tensor directly from data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([5.5, 3])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###### create a tensor based on an existing tensor. \n",
    " These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([2.0551, 0.6875])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "y = torch.randn_like(y, dtype=torch.float)    # override dtype!\n",
    "print(y)\n",
    "print(y.size()) #torch.Size is in fact a tuple, so it supports all tuple operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0719, 0.5628, 0.3523, 0.3193],\n",
      "        [0.5753, 0.1280, 0.3894, 0.1557],\n",
      "        [0.1336, 0.6422, 0.5267, 0.4748]])\n",
      "tensor([[0.5894, 0.0928, 0.0994, 0.2394],\n",
      "        [0.0759, 0.9523, 0.6718, 0.6349],\n",
      "        [0.9774, 0.4634, 0.1530, 0.2365]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(3,4)\n",
    "print(a)\n",
    "b=torch.rand(3,4)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8400, 0.8413, 0.6503, 1.0374],\n",
      "        [0.8029, 2.9849, 2.4048, 2.0603],\n",
      "        [3.0658, 2.0324, 0.9858, 1.1841]])\n",
      "tensor([[1.8400, 0.8413, 0.6503, 1.0374],\n",
      "        [0.8029, 2.9849, 2.4048, 2.0603],\n",
      "        [3.0658, 2.0324, 0.9858, 1.1841]])\n",
      "tensor([[1.8400, 0.8413, 0.6503, 1.0374],\n",
      "        [0.8029, 2.9849, 2.4048, 2.0603],\n",
      "        [3.0658, 2.0324, 0.9858, 1.1841]])\n"
     ]
    }
   ],
   "source": [
    "print(a+b)\n",
    "##\n",
    "res=torch.empty_like(a)\n",
    "torch.add(a,b,out=res)\n",
    "print(res)\n",
    "###\n",
    "a.add_(b)\n",
    "print(a)\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _. \n",
    "# For example: x.copy_(y), x.t_(), will change x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use standard NumPy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### reshape or resize the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8400, 0.8413, 0.6503, 1.0374, 0.8029, 2.9849, 2.4048, 2.0603, 3.0658,\n",
      "        2.0324, 0.9858, 1.1841])\n",
      "tensor([[1.8400, 0.8413],\n",
      "        [0.6503, 1.0374],\n",
      "        [0.8029, 2.9849],\n",
      "        [2.4048, 2.0603],\n",
      "        [3.0658, 2.0324],\n",
      "        [0.9858, 1.1841]])\n"
     ]
    }
   ],
   "source": [
    "c=a.view(12)\n",
    "print(c)\n",
    "d=a.view(-1,2)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7535])\n",
      "0.753531277179718\n"
     ]
    }
   ],
   "source": [
    "# if you have a one element tensor, \n",
    "# use .item() to get the value as a Python number\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[more opeartions](https://pytorch.org/docs/torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NumPy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.840004   0.84129965 0.6503469  1.0373697 ]\n",
      " [0.8029381  2.984898   2.404752   2.0603335 ]\n",
      " [3.0657861  2.0324054  0.9857589  1.1841494 ]]\n"
     ]
    }
   ],
   "source": [
    "e = a.numpy()\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "g = np.ones(5)\n",
    "f = torch.from_numpy(g)\n",
    "np.add(g, 1, out=g)\n",
    "print(g)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CUDA tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors can be moved onto any device using the .to method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
